# WrenAI Configuration for Gemini 2.5 Flash (Docker-free Setup)
# This configuration uses local services instead of Docker containers
# Place this file as config.yaml in your ~/.wrenai directory
# Set GEMINI_API_KEY=<your_api_key> in ~/.wrenai/.env

type: llm
provider: litellm_llm
models:
  # Gemini 2.5 Flash model configuration
  - model: gemini/gemini-2.0-flash-exp # Latest Gemini 2.5 Flash experimental model
    alias: default
    timeout: 120
    kwargs:
      n: 1
      temperature: 0
  - model: gemini/gemini-2.0-flash-exp
    alias: gemini-llm-for-chart
    timeout: 120
    kwargs:
      n: 1
      temperature: 0
      response_format:
        type: json_object

---
type: embedder
provider: litellm_embedder
models:
  # Gemini text embedding model
  - model: gemini/text-embedding-004
    alias: default
    timeout: 120
    kwargs:
      dimensions: 768

---
type: document_store
provider: qdrant_document_store
config:
  host: localhost
  port: 6333
  collection_name: wren_ai_collection
  embedding_dimension: 768
  distance_metric: cosine

---
type: engine
provider: wren_ui
config:
  endpoint: http://localhost:3000

---
# Local Services Configuration (Docker-free)
type: local_services
config:
  wren_engine:
    host: localhost
    port: 8080
    endpoint: http://localhost:8080
  ibis_server:
    host: localhost
    port: 8000
    endpoint: http://localhost:8000

---
type: pipeline
name: db_schema_indexing
llm: default
embedder: default
document_store: default

---
type: pipeline
name: sql_generation
llm: default
embedder: default
document_store: default

---
type: pipeline
name: chart_generation
llm: gemini-llm-for-chart